{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to prototype different models for predicting voter turnout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris_ibt8rn4\\Anaconda3\\envs\\cms155\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in training data\n",
    "data_train = pd.read_csv(os.path.join('data', 'train_2008.csv'))\n",
    "\n",
    "# Extract input features and output labels\n",
    "X_train = data_train.values[:, 1:-1]\n",
    "y_train = data_train.values[:, -1]\n",
    "\n",
    "# Define training set for hyperparameter selection\n",
    "inds = np.arange(len(X_train))[:10000]\n",
    "X = X_train[inds]\n",
    "y = y_train[inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then train random forest classifiers, including hyperparameter selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyperparameters for tuning\n",
    "parameters = {'n_estimators': np.arange(1000, 3100, 100),\n",
    "              'max_features': np.arange(15, 65, 5),\n",
    "              'min_samples_leaf': np.arange(0.0001, 0.005, 0.0001),\n",
    "              'max_depth': [None] + list(np.arange(10, 55, 5))}\n",
    "\n",
    "# Perform hyperparameter testing\n",
    "clf = RandomizedSearchCV(RandomForestClassifier(), parameters,\n",
    "                         scoring='roc_auc', return_train_score=True,\n",
    "                         n_iter=10, n_jobs=-1)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Save results\n",
    "filename = 'RandomForest_{:s}.pkl'.format(time.strftime('%Y%m%d-%H%M'))\n",
    "#with open(filename, 'wb') as file:\n",
    "#    pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I read in the results, extract the best estimator, and train it to the full training data.  This final model is then used to make predictions on the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC (training): 0.7925537920915184\n"
     ]
    }
   ],
   "source": [
    "# Specify file name\n",
    "#filename = ''\n",
    "\n",
    "# Read in results\n",
    "#with open(filename, 'rb') as file:\n",
    "#    clf = pickle.load(file)\n",
    "\n",
    "# Train best estimator\n",
    "model = clf.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Show score on training set\n",
    "print('ROC AUC (training):',\n",
    "      roc_auc_score(y_train, model.predict_proba(X_train)[:, 1]))\n",
    "\n",
    "# Read in input data for test sets\n",
    "test_2008 = pd.read_csv(os.path.join('data', 'test_2008.csv'))\n",
    "test_2012 = pd.read_csv(os.path.join('data', 'test_2012.csv'))\n",
    "\n",
    "# Make predictions on test sets\n",
    "pred_2008 = model.predict_proba(test_2008.values[:, 1:])[:, 1]\n",
    "pred_2012 = model.predict_proba(test_2012.values[:, 1:])[:, 1]\n",
    "\n",
    "# Write results\n",
    "df_2008 = pd.DataFrame(data={'id': test_2008.values[:, 0],\n",
    "                             'target': pred_2008})\n",
    "df_2008.to_csv(os.path.join('predictions', 'pred_2008_CS.csv'),\n",
    "               index=None, header=True)\n",
    "df_2012 = pd.DataFrame(data={'id': test_2012.values[:, 0],\n",
    "                             'target': pred_2012})\n",
    "df_2012.to_csv(os.path.join('predictions', 'pred_2012_CS.csv'),\n",
    "               index=None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also note experiments with other modeling choices that were not used for the final training, including the following:\n",
    "- Scaling the input data\n",
    "- Resampling the input data for balanced classes\n",
    "- Performing feature selection using Yitong's features (code not shown)\n",
    "- Using logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Scale data\n",
    "X = preprocessing.scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample data to represent both classes equally\n",
    "inds_neg = np.where(y_train == 0)[0]\n",
    "inds_pos = np.where(y_train == 1)[0]\n",
    "inds = np.concatenate((inds_neg,\n",
    "                       np.random.choice(inds_pos, size=len(inds_neg),\n",
    "                                        replace=True)))\n",
    "np.random.shuffle(inds)\n",
    "X = X_train[inds]\n",
    "y = y_train[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train logistic regression model with different regularization strengths\n",
    "parameters = {'C': np.logspace(-2, 2, 9)}\n",
    "clf = RandomizedSearchCV(LogisticRegression(), parameters,\n",
    "                         scoring='roc_auc', return_train_score=True,\n",
    "                         n_iter=1, n_jobs=-1)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(clf.cv_results_['params'][i], clf.cv_results_['mean_test_score'][i])\n",
    " for i in np.argsort(clf.cv_results_['rank_test_score'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
